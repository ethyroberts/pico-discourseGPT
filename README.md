# DiscourseGPT
A short demo using a letter-based GPT model trained on South African hate speech data. The model is trained in the same way as Andrej Karpathy's nanoGPT, though generates data of the form of SA Twitter/X discourse. 

Best to substantially reduce the number of iterations in `gpt.py` if you only have a CPU. Training the model takes more than 10 minutes on a GPU. The sample data file is 150x smaller than the full dataset, and is a good option to use for testing purposes.

Feel free to contact me should you like access to the private repo that houses the data used here :)
